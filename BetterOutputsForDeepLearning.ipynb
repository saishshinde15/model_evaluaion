{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhVfcAl33yJZfcYTba4Edt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishshinde15/model_evaluaion/blob/main/BetterOutputsForDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "early stopping the fitting process"
      ],
      "metadata": {
        "id": "Fsd3wQf2rIsm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsbr2WV6qp8m"
      },
      "outputs": [],
      "source": [
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(X_train_features, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "Fr4uFmJpqszM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save(\"parkinson_detection_model2.keras\")"
      ],
      "metadata": {
        "id": "WarlOhKFqvf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history2.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "47gzGoiNqx2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history2.history['loss'], label='Training Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-OjcbXYyq12Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using learning schedular to dtermine the learining rate"
      ],
      "metadata": {
        "id": "cAg5su1SrPMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch"
      ],
      "metadata": {
        "id": "y8um5RajrZPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_9.fit(X_train,\n",
        "                      y_train,\n",
        "                      epochs=100,\n",
        "                      callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "iT_pOw_EraVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate versus the loss\n",
        "lrs = 1e-4 * (10 ** (np.arange(100)/20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. loss\");"
      ],
      "metadata": {
        "id": "ukkITV-srddO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the rule of thumb is to take the learning rate value where the loss is still decreasing but not quite flattened out"
      ],
      "metadata": {
        "id": "t6jk6uB6riGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of other typical learning rate values\n",
        "10**0, 10**-1, 10**-2, 10**-3, 1e-4"
      ],
      "metadata": {
        "id": "IPfmbaLXrl_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://dev.mrdbourke.com/tensorflow-deep-learning/02_neural_network_classification_in_tensorflow/"
      ],
      "metadata": {
        "id": "5LuaQI5Or5xr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNUvQEzRr72t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}